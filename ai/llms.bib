@ARTICLE{Hicks2024-tp,
  title = {{ChatGPT is bullshit}},
  author = {Hicks, Michael Townsen and Humphries, James and Slater, Joe},
  journaltitle = {Ethics Inf. Technol.},
  publisher = {Springer Science and Business Media LLC},
  volume = {26},
  issue = {2},
  pages = {1--10},
  date = {2024-06-08},
  doi = {10.1007/s10676-024-09775-5},
  issn = {1388-1957,1572-8439},
  abstract = {AbstractRecently, there has been considerable interest in large
  language models: machine learning systems which produce human-like text and
  dialogue. Applications of these systems have been plagued by persistent
  inaccuracies in their output; these are often called “AI hallucinations”. We
  argue that these falsehoods, and the overall activity of large language
  models, is better understood as bullshit in the sense explored by Frankfurt
  (On Bullshit, Princeton, 2005): the models are in an important way indifferent
  to the truth of their outputs. We distinguish two ways in which the models can
  be said to be bullshitters, and argue that they clearly meet at least one of
  these definitions. We further argue that describing AI misrepresentations as
  bullshit is both a more useful and more accurate way of predicting and
  discussing the behaviour of these systems.},
  url = {https://link.springer.com/article/10.1007/s10676-024-09775-5},
  urldate = {2025-01-16},
  file = {All_Papers/H/Hicks_et_al._2024_-_ChatGPT_is_bullshit.pdf},
  language = {en}
}

@MISC{Chiang2024-zt,
  title = {{Why A.I. Isn’t Going to Make Art}},
  author = {Chiang, Ted},
  journaltitle = {The New Yorker},
  publisher = {The New Yorker},
  date = {2024-08-31},
  issn = {0028-792X},
  abstract = {Ted Chiang on how artificial intelligence still isn’t as
  intelligent as it is perceived to be and how its profound limitations should
  temper our fears about it replacing real art-making.},
  url = {https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art},
  urldate = {2025-08-14}
}

@MISC{Rosenzweig2023-jh,
  title = {{The trouble with using Google and Microsoft's AI writing assistants}},
  author = {Rosenzweig, Jane},
  journaltitle = {Los Angeles Times},
  publisher = {Los Angeles Times},
  date = {2023-06-20},
  issn = {0458-3035,2165-1736},
  abstract = {AI is on the verge of becoming a standard feature of word
  processing. The danger is that it will discourage us from thinking for
  ourselves.},
  url = {https://www.latimes.com/opinion/story/2023-06-20/google-microsoft-chatgpt-ai-writing-assistants-artificial-intelligence},
  urldate = {2025-08-14}
}



@ARTICLE{Hannigan2024-cv,
  title = {{Beware of botshit: How to manage the epistemic risks of generative
  chatbots}},
  author = {Hannigan, Timothy R and McCarthy, Ian P and Spicer, André},
  journaltitle = {Bus. Horiz.},
  publisher = {Elsevier BV},
  volume = {67},
  issue = {5},
  pages = {471--486},
  date = {2024-03-01},
  doi = {10.1016/j.bushor.2024.03.001},
  issn = {0007-6813,1873-6068},
  abstract = {Advances in large language model (LLM) technology enable chatbots
  to generate and analyze content for our work. Generative chatbots do this work
  by pr…},
  url = {http://dx.doi.org/10.1016/j.bushor.2024.03.001},
  urldate = {2025-01-16},
  language = {en}
}


@book{frankfurt_bullshit_2005,
	address = {Princeton, NJ},
	title = {On bullshit},
	isbn = {978-0-691-12294-6},
	publisher = {Princeton University Press},
	author = {Frankfurt, Harry G.},
	year = {2005},
	keywords = {Truthfulness and falsehood},
}
