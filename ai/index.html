<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-08-14">
<meta name="description" content="How and why I use (or, don’t use) AI and LLMs in my work and thinking">

<title>AI – Vivek Srikrishnan</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-b5198e082568c168c5f3209179708e59.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-6db3fe8f292d27f1a8cdef22494519b5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/fontawesome6-1.2.0/all.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/fontawesome6-1.2.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<meta name="twitter:title" content="AI – Vivek Srikrishnan">
<meta name="twitter:description" content="How and why I use (or, don’t use) AI and LLMs in my work and thinking">
<meta name="twitter:card" content="summary">
</head>

<body class="floating nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Vivek Srikrishnan</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../cv/index.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../now/index.html"> 
<span class="menu-text">Now</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../ai/index.html" aria-current="page"> 
<span class="menu-text">AI</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../contact/index.html"> 
<span class="menu-text">Contact</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Areas</h2>
   
  <ul>
  <li><a href="#usage" id="toc-usage" class="nav-link active" data-scroll-target="#usage">Usage</a></li>
  <li><a href="#principles" id="toc-principles" class="nav-link" data-scroll-target="#principles">Principles</a></li>
  <li><a href="#text" id="toc-text" class="nav-link" data-scroll-target="#text">Text</a></li>
  <li><a href="#images-and-video" id="toc-images-and-video" class="nav-link" data-scroll-target="#images-and-video">Images and Video</a></li>
  <li><a href="#research" id="toc-research" class="nav-link" data-scroll-target="#research">Research</a></li>
  <li><a href="#programming" id="toc-programming" class="nav-link" data-scroll-target="#programming">Programming</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">AI</h1>
</div>

<div>
  <div class="description">
    How and why I use (or, don’t use) AI and LLMs in my work and thinking
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Last updated</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2025-08-14</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>This is my <a href="https://www.bydamo.la/p/ai-manifesto">/ai page</a>, where, in the interest of full transparency, I make explicit how I use AI in my work and what the underlying thoughts and principles are that guide that usage.</p>
<section id="usage" class="level2">
<h2 class="anchored" data-anchor-id="usage">Usage</h2>
<p>None of the content on this website or my <a href="https://viveks.bee.cornell.edu">lab group’s website</a> were written, in part or in full, by a generative AI tool (more specifically, large language models, or LLMs).</p>
<p>I do not, and will not, intentionally write text or generate figures using LLMs (though with the increasing integration of these tools into word processors, some usage may leak in accidentally). I have occasionally (not often!) used LLMs to generate starter code for certain programming tasks (web scraping, for example), but debug and refine this code manually.</p>
<p>I also try to block AI bots from accessing and scraping from parsing this and any other websites I create using the associated <code>robots.txt</code>: any scraping that occurs is in violation of this access condition.</p>
</section>
<section id="principles" class="level2">
<h2 class="anchored" data-anchor-id="principles">Principles</h2>
<p>I enjoy the act (and sometimes struggle!) of writing and programming. While LLMs can be helpful tools for certain things, they are useless (or at least awful) for others, and always involve ethical and environmental tradeoffs that should be navigated intentionally.</p>
<p>I am not opposed to the <em>thoughtful</em> use of LLMs. Contrary to the endless hype and marketing served by their creators and the media, these tools have strong limitations and over-reliance on them can greatly impede the discovery and learning processes. As Ted Chiang wrote, <a href="https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art">“Using ChatGPT to complete assignments is like bringing a forklift into the weight room; you will never improve your cognitive fitness that way.”</a><span class="citation" data-cites="Chiang2024-zt">(<a href="#ref-Chiang2024-zt" role="doc-biblioref">1</a>)</span></p>
<p><strong>Moreover</strong>:</p>
<ul>
<li>The scalable models are provided <a href="https://www.wheresyoured.at/anthropic-and-openai-have-begun-the-subprime-ai-crisis/">at a great monetary loss</a> <a href="https://www.wheresyoured.at/anthropic-is-bleeding-out/">to their companies</a>, which means they might be <em>far</em> more expensive (or even not available) in the future — do you want to be dependent on them if that occurs? At the same time, <a href="https://www.derekthompson.org/p/how-ai-conquered-the-us-economy-a">AI companies have been responsible for 60% of the stock market’s growth between 2023–2025, and AI capital expenditures, as a function of GDP, have outpaced those during the dot-com boom</a>. The combination of these factors <a href="https://www.wheresyoured.at/the-haters-gui/">suggests that the U.S. economy is in the middle of an unsustainable bubble driven by AI hype</a></li>
<li>They <a href="https://www.anthropic.com/research/reasoning-models-dont-say-think">do not reason the way humans do</a> and, even so-called “reasoning models” will only generate statistically-plausible text when asked to explain their output. This informs some of the thoughts on applications below: in cases where LLM output is used as a jumping off point and everything will be manually checked, this limitation is not as important, but if LLMs are being used to “answer” a question…good luck.</li>
<li>Data centers used to train large-scale LLMs also have <a href="https://news.mit.edu/2025/explained-generative-ai-environmental-impact-0117">large environmental impacts</a>, increasing electricity and water demands and placing an increasing strain on our already-straining infrastructure systems.</li>
<li>If the output of these models isn’t legally plagiarism, <a href="https://nickfthilton.medium.com/llms-are-definitionally-plagiaristic-fc8c00299ae3">it isn’t functionally far off</a>.</li>
<li><a href="https://www.liberalcurrents.com/half-the-answer-27-ai-as-a-political-project/">“AI”, as currently discussed and deployed, is a political project</a>, and we should reckon with the implications of that project every time we use these tools or products which integrate them. That doesn’t mean these tools shouldn’t be used, but they should be used deliberately and with an understanding that we are engaging in a task that is, at best, ethically dubious.</li>
</ul>
</section>
<section id="text" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="text">Text</h2>
<p>I am opposed to the use of LLMs for writing other than formulaic tasks like re-formatting existing text or tweaking grammar (particularly if English is a second language)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. The <a href="https://www.latimes.com/opinion/story/2023-06-20/google-microsoft-chatgpt-ai-writing-assistants-artificial-intelligence">process of writing is the process of thinking</a><span class="citation" data-cites="Rosenzweig2023-jh">(<a href="#ref-Rosenzweig2023-jh" role="doc-biblioref">2</a>)</span>; using LLMs to write means your ideas are likely to be half-baked and you are less likely to understand feedback because you did not think through and articulate your ideas<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Moreover, LLMs flatten styles, even with prompt engineering: I find reading LLM-generated text to be an uninspiring slog. To paraphrase <a href="https://www.bbc.com/news/articles/c15q5qzdjqxo">Sabrine Zetteler</a>, why would I want to read something that the “author” couldn’t bother to put effort into writing?</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;But I still don’t like using tools for these purposes: changing grammar can change the ways sentences parse and communicate meaning</p></div><div id="fn2"><p><sup>2</sup>&nbsp;As far as I can tell, much of the appeal of using LLMs to generate text is to avoid the struggle of refining ideas through writing.</p></div></div><p>The fundamental problem with LLMs is that they are <strong>bullshit generators</strong> <span class="citation" data-cites="Hicks2024-tp Hannigan2024-cv">(<a href="#ref-Hicks2024-tp" role="doc-biblioref">3</a>, <a href="#ref-Hannigan2024-cv" role="doc-biblioref">4</a>)</span>. Bullshit, in the philosophical sense, is text produced without care for the truth <span class="citation" data-cites="frankfurt_bullshit_2005">(<a href="#ref-frankfurt_bullshit_2005" role="doc-biblioref">5</a>)</span>. It is not a <em>lie</em>, which specifically exists in opposition of truth, or a <em>mistake</em>, which is subject to correction when exposed to divergence from the truth, but it is agnostic to the truth; it simply exists to make the author sound like an authority. Truth simply does not matter to a bullshitter.</p>
<p>LLMs literally exist only to produce bullshit. They use a predictive statistical model to guess what next word (or sequence of words) is likely; there is no reference to whether the underlying idea produced by this sequence of words is truthful or even coherent<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. This means that, once an LLM goes off track, they are subject to wild hallucinations where they may invent concepts or artifacts (books, articles, etc) that do not exist, merely because they <em>seem plausible as a string of text</em><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. This fundamentally affects the reliability of LLM results for information retrieval<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. Additionally, given that LLMs are trained on publicly available text, an increasing amount of which is now generated by LLMs (so-called <strong>“AI slop”</strong>), the uncritical use of these results can just perpetuate the bullshit cycle.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;To paraphrase <a href="http://bactra.org/weblog/feral-library-card-catalogs.html">Cosma Shalizi</a>, the appearance that LLMs “reason” or have insights is an <a href="http://arxiv.org/abs/2309.13638">ember of autoregression</a> sprinkled with <a href="https://arxiv.org/abs/2104.12871">wishful mnemonics</a></p></div><div id="fn4"><p><sup>4</sup>&nbsp;Even worse, <a href="https://www.anthropic.com/research/tracing-thoughts-language-model">there is evidence that LLMs will just give a plausible-seeming argument instead of following logical steps or transparently communicating their reasoning, even when they are instructed to make their reasoning transparent</a>.</p></div><div id="fn5"><p><sup>5</sup>&nbsp;As put by <a href="https://buttondown.com/maiht3k/archive/information-literacy-and-chatbots-as-search/">computational linguist Emily Bender</a>, “If someone uses an LLM as a replacement for search, and the output they get is correct, this is just by chance. Furthermore, a system that is right 95% of the time is arguably more dangerous tthan [<em>sic</em>] one that is right 50% of the time. People will be more likely to trust the output, and likely less able to fact check the 5%.” It’s worth reading the whole post about how using LLM summaries as a substitute for search harms information literacy and disrupts sense-making processes.</p></div></div></section>
<section id="images-and-video" class="level2">
<h2 class="anchored" data-anchor-id="images-and-video">Images and Video</h2>
<p>I find the style of LLM-generated “art” to be, worse than uninteresting: it’s actively off-putting and repulsive. I’m not opposed to using machine learning for targeted tasks, like color fills and object selection, is <em>fine</em>, but LLMs being shoehorned onto those tasks is unnecessary and kind of like using a sledgehammer to crack a nut.</p>
</section>
<section id="research" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="research">Research</h2>
<p>Using LLMs as a substitute for literature reviews and idea synthesis short-cuts the learning and thinking process<span class="citation" data-cites="Chiang2024-zt">(<a href="#ref-Chiang2024-zt" role="doc-biblioref">1</a>)</span> and <a href="https://hai.stanford.edu/news/hallucinating-law-legal-mistakes-large-language-models-are-pervasive">can often result</a> <a href="https://www.washingtonpost.com/health/2025/05/29/maha-rfk-jr-ai-garble/">in the insertion of hallucinations</a>. LLMs can also lead to <a href="https://www.nytimes.com/2025/08/08/technology/ai-chatbots-delusions-chatgpt.html">dangerous spiraling behavior</a> by encouraging incorrect ideas and thoughts.</p>
<p>As always, there are much more limited applications where LLMs could be useful. I can imagine that using an LLM to give a starting set of references, <strong>which will be read manually</strong>, might be more useful to some people than slogging through Google Scholar<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. Hallucinations would therefore not be an issue: you just wouldn’t find those articles, and you can expand your review by following citations and references.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;It might also be useful to use an LLM to generate a set of search terms for Google Scholar.</p></div></div></section>
<section id="programming" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="programming">Programming</h2>
<p>While I personally don’t often use LLMs for any programming tasks<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>, I’m not opposed to their use in the same way that I am with writing. In my experience, LLM autocompletions aren’t great, but they’re <em>fine</em><a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>, and scientific programming is not necessarily focused on efficiency at all costs. Using LLMs to translate code between languages, to generate documentation, and to interpret error messages are all very reasonable.</p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;Debugging is frustrating, but it teaches me something about the language.</p></div><div id="fn8"><p><sup>8</sup>&nbsp;Just beware of <a href="https://www.trendmicro.com/vinfo/us/security/news/cybercrime-and-digital-threats/slopsquatting-when-ai-agents-hallucinate-malicious-packages">slopsquatting</a>!</p></div></div></section>
<section id="references" class="level2">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" role="list">
<div id="ref-Chiang2024-zt" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">T. Chiang, <a href="https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art"><span class="nocase">Why A.I. Isn’t Going to Make Art</span></a>. <em>The New Yorker</em> (2024).</div>
</div>
<div id="ref-Rosenzweig2023-jh" class="csl-entry" role="listitem">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">J. Rosenzweig, <a href="https://www.latimes.com/opinion/story/2023-06-20/google-microsoft-chatgpt-ai-writing-assistants-artificial-intelligence"><span class="nocase">The trouble with using Google and Microsoft’s AI writing assistants</span></a>. <em>Los Angeles Times</em> (2023).</div>
</div>
<div id="ref-Hicks2024-tp" class="csl-entry" role="listitem">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">M. T. Hicks, J. Humphries, J. Slater, <a href="https://doi.org/10.1007/s10676-024-09775-5"><span class="nocase">ChatGPT is bullshit</span></a>. <em>Ethics Inf. Technol.</em> <strong>26</strong>, 1–10 (2024).</div>
</div>
<div id="ref-Hannigan2024-cv" class="csl-entry" role="listitem">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">T. R. Hannigan, I. P. McCarthy, A. Spicer, <a href="https://doi.org/10.1016/j.bushor.2024.03.001"><span class="nocase">Beware of botshit: How to manage the epistemic risks of generative chatbots</span></a>. <em>Bus. Horiz.</em> <strong>67</strong>, 471–486 (2024).</div>
</div>
<div id="ref-frankfurt_bullshit_2005" class="csl-entry" role="listitem">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">H. G. Frankfurt, <em>On bullshit</em> (Princeton University Press, 2005).</div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/viveks\.me");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block"><i class="fa-brands fa-creative-commons" aria-label="creative-commons"></i> 2021-2025 Vivek Srikrishnan</span> <span class="faux-block">All content licensed under<br><a href="https://creativecommons.org/licenses/by/4.0/"><i class="fa-brands fa-creative-commons" aria-label="creative-commons"></i> <i class="fa-brands fa-creative-commons-by" aria-label="creative-commons-by"></i> Creative Commons CC BY 4.0</a></span></p>
</div>   
    <div class="nav-footer-center">
<p>Made with <a href="https://quarto.org/"><img src="https://quarto.org/quarto.png" class="img-fluid" alt="Quarto" width="65"></a><br> See the <a href="../about.html">About Page</a> for credit information.</p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/vsrikrish/vsrikrish-quarto">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>